{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDER CONSTRUCTION\n",
    "\n",
    "This notebook is still a work in progress and may not work as intended. You have been warned!\n",
    "\n",
    "# Boots 'n' Cats 2c: Modelling with a Custom MXNet Algorithm\n",
    "\n",
    "In this notebook we'll try another approach to build our boots 'n' cats detector: a YOLOv3 implementation on SageMaker's [MXNet container](https://sagemaker.readthedocs.io/en/stable/using_mxnet.html).\n",
    "\n",
    "SageMaker supports fully custom containers, but also offers pre-optimized environments for the major ML frameworks TensorFlow, PyTorch, and MXNet; which streamline typical workflows.\n",
    "\n",
    "The interface mechanisms (channels, endpoints, etc) work the same as for the built-in algorithms, but now we're authoring a Python package loaded by the framework application inside the base container: So need to understand the interfaces through which our code consumes inputs and exposes results and parameters.\n",
    "\n",
    "**You'll need to** have gone through the first notebook in this series (*Intro and Data Preparation*) to complete this example.\n",
    "\n",
    "## About the Algorithm: YOLOv3\n",
    "\n",
    "As discussed with reference to benchmarks on the project [website](https://pjreddie.com/darknet/yolo/) and detailed in the [original paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf) (Redmon et al, 2016), YOLO (\"You Only Look Once\") is another highly successful object detection algorithm alongside SSD as implemented in the SageMaker built-in algorithm.\n",
    "\n",
    "Both YOLO and SSD are \"one-stage detectors\", in contrast to previous R-CNN group methods which separately 1) propose and then 2) validate and adjust bounding boxes. Tackling the region proposal and classification/validation problems together gives these architectures significant speed benefits at comparable accuracy.\n",
    "\n",
    "Whereas SSD creates convolutional \"feature maps\" at different scales and learns to predict the offset of \"anchor boxes\" relative to those; YOLO in parallel computes \"class probabilities\" on subdivided grid squares of the image, and bounding box coordinates for likely objects - before correlating the two together.\n",
    "\n",
    "A nice comparison of the methods is presented [here](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html). Recent advances in YOLO (v2 and v3 releases) have led to it achieving better accuracy than SSD at comparable model sizes / speeds in some benchmarks, as shown in the below graph reproduced from the [GluonCV Model Zoo](https://gluon-cv.mxnet.io/model_zoo/detection.html)\n",
    "\n",
    "<img src=\"BlogImages/GluonCVYOLOvsSSD.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Dependencies and configuration\n",
    "\n",
    "As usual we'll start by loading libraries, defining configuration, and connecting to the AWS SDKs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Built-Ins:\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import imageio\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet as SageMakerMXNet\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Local Dependencies:\n",
    "%aimport util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we re-load configuration from the intro & data processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r BUCKET_NAME\n",
    "assert BUCKET_NAME, \"BUCKET_NAME missing from IPython store\"\n",
    "%store -r CHECKPOINTS_PREFIX\n",
    "assert CHECKPOINTS_PREFIX, \"CHECKPOINTS_PREFIX missing from IPython store\"\n",
    "%store -r DATA_PREFIX\n",
    "assert DATA_PREFIX, \"DATA_PREFIX missing from IPython store\"\n",
    "%store -r MODELS_PREFIX\n",
    "assert MODELS_PREFIX, \"MODELS_PREFIX missing from IPython store\"\n",
    "%store -r CLASS_NAMES\n",
    "assert CLASS_NAMES, \"CLASS_NAMES missing from IPython store\"\n",
    "%store -r test_image_folder\n",
    "assert test_image_folder, \"test_image_folder missing from IPython store\"\n",
    "\n",
    "%store -r attribute_names\n",
    "assert attribute_names, \"attribute_names missing from IPython store\"\n",
    "%store -r n_samples_training\n",
    "assert n_samples_training, \"n_samples_training missing from IPython store\"\n",
    "%store -r n_samples_validation\n",
    "assert n_samples_validation, \"n_samples_validation missing from IPython store\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just connect to the AWS SDKs we'll use, and validate the choice of S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "s3 = session.resource(\"s3\")\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "smclient = session.client(\"sagemaker\")\n",
    "\n",
    "bucket_region = \\\n",
    "    session.client(\"s3\").head_bucket(Bucket=BUCKET_NAME)[\"ResponseMetadata\"][\"HTTPHeaders\"][\"x-amz-bucket-region\"]\n",
    "assert (\n",
    "    bucket_region == region\n",
    "), f\"Your S3 bucket {BUCKET_NAME} and this notebook need to be in the same region.\"\n",
    "\n",
    "if (region != \"us-east-1\"):\n",
    "    print(\"WARNING: Rekognition Custom Labels functionality is only available in us-east-1 at launch\")\n",
    "    \n",
    "# Initialise some empty variables we need to exist:\n",
    "predictor_std = None\n",
    "predictor_hpo = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Review our algorithm details\n",
    "\n",
    "We'll use the GluonCV (a deep learning framework built on MXNet) implementation of YOLOv3, and run it on top of the SageMaker-provided MXNet container.\n",
    "\n",
    "As detailed in the [SageMaker Python SDK docs](https://sagemaker.readthedocs.io/en/stable/using_mxnet.html), our job is to implement a Python file (or bundle of files with a designated entry point) that:\n",
    "\n",
    "* When run as a script, performs model training and saves the resultant model artifacts\n",
    "* When imported as a module, defines functions which the framework server application can call to load the model; perform inference; and deserialize/serialize data from and to the web.\n",
    "\n",
    "In cases like this one where extra dependencies (or newer versions) are required vs the base container, there are two options:\n",
    "\n",
    "* Define a custom container, and take on the effort of re-implementing (or inheriting) the framework server application code\n",
    "* Performing a `pip install` in the code itself, executed when the file is loaded.\n",
    "\n",
    "The latter option increases the billable execution time in training, and the latency for new container instances to spin-up in deployed endpoint auto-scaling... But for a small number of additional packages these costs can be preferable versus the complexity of fully customizing the container.\n",
    "\n",
    "Take some time to look through our implementation at the location below in this repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point=\"yolo_train.py\"\n",
    "source_dir=\"src\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with built-in algorithms, the choices we make in implementation will have consequences including for example:\n",
    "\n",
    "* Whether distributed training is supported\n",
    "* Whether GPU-accelerated instances will provide any performance benefits\n",
    "* What data formats are supported for training and inference\n",
    "* How data is loaded into the container at training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set up input data channels\n",
    "\n",
    "**TODO: Notes on how & why this differs from built-in algo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.session.s3_input(\n",
    "    f\"s3://{BUCKET_NAME}/{DATA_PREFIX}/train.manifest\",\n",
    "    distribution=\"FullyReplicated\",  # In case we want to try distributed training\n",
    "    #content_type=\"application/x-recordio\",\n",
    "    #s3_data_type=\"ManifestFile\",\n",
    "    #record_wrapping=\"RecordIO\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    attribute_names=attribute_names  # In case the manifest contains other junk to ignore (it does!)\n",
    ")\n",
    "                                        \n",
    "validation_channel = sagemaker.session.s3_input(\n",
    "    f\"s3://{BUCKET_NAME}/{DATA_PREFIX}/validation.manifest\",\n",
    "    distribution=\"FullyReplicated\",\n",
    "    #content_type=\"application/x-recordio\",\n",
    "    #record_wrapping=\"RecordIO\",\n",
    "    #s3_data_type=\"ManifestFile\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    attribute_names=attribute_names\n",
    ")\n",
    "\n",
    "image_channel = sagemaker.session.s3_input(\n",
    "    f\"s3://{BUCKET_NAME}/\",\n",
    "    s3_data_type=\"S3Prefix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure the algorithm\n",
    "\n",
    "**TODO: Notes on how & why this differs from built-in algo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SageMakerMXNet(\n",
    "    role=role,\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    framework_version=\"1.4.1\",\n",
    "    py_version=\"py3\",\n",
    "    input_mode=\"File\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.p3.8xlarge\",\n",
    "    train_max_run=5*60*60,\n",
    "    train_use_spot_instances=True,\n",
    "    train_max_wait=5*60*60,\n",
    "    metric_definitions=[\n",
    "        {'Name': 'validation:MeanAP', 'Regex': 'Validation: VOCMeanAP=(.*?) ;'},\n",
    "        {'Name': 'train:MeanAP', 'Regex': 'Train: VOCMeanAP=(.*?) ;'},\n",
    "    ],\n",
    "    base_job_name=\"bootsncats-yolo\",\n",
    "    output_path=f\"s3://{BUCKET_NAME}/{MODELS_PREFIX}\",\n",
    "    checkpoint_s3_uri=f\"s3://{BUCKET_NAME}/{CHECKPOINTS_PREFIX}\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": 10,\n",
    "        \"num-workers\": 4,\n",
    "        \"batch-size\": 4,\n",
    "        \"num-gpus\": 4,\n",
    "        \"data-shape\": 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the model\n",
    "\n",
    "As with the built-in algorithms, we have the choice between fitting our model with the given set of hyperparameters or performing automatic hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH_HPO = # TODO: True first, then False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if (not WITH_HPO):\n",
    "    estimator.fit(\n",
    "        {\n",
    "            \"train\": train_channel,\n",
    "            \"test\": validation_channel,\n",
    "            \"images\": image_channel\n",
    "        },\n",
    "        logs=True\n",
    "    )\n",
    "else:\n",
    "    hyperparameter_ranges = {\n",
    "        \"learning_rate\": sagemaker.tuner.ContinuousParameter(0.0001, 0.1),\n",
    "        \"momentum\": sagemaker.tuner.ContinuousParameter(0.0, 0.99),\n",
    "        \"weight_decay\": sagemaker.tuner.ContinuousParameter(0.0, 0.99),\n",
    "        \"mini_batch_size\": sagemaker.tuner.IntegerParameter(1, n_samples_validation),\n",
    "        \"optimizer\": sagemaker.tuner.CategoricalParameter(['sgd', 'adam', 'rmsprop', 'adadelta'])\n",
    "    }\n",
    "\n",
    "    tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "        estimator,\n",
    "        \"validation:mAP\",  # Name of the objective metric to optimize\n",
    "        objective_type=\"Maximize\",  # \"Mean Average Precision\" high = good\n",
    "        hyperparameter_ranges=hyperparameter_ranges,\n",
    "        base_tuning_job_name=\"bootsncats-ssd-hpo\",\n",
    "        # `max_jobs` obviously has cost implications, but the optimization can always be terminated:\n",
    "        max_jobs=24,\n",
    "        max_parallel_jobs=3  # Keep sensible for the configured max_jobs...\n",
    "    )\n",
    "    \n",
    "    tuner.fit(\n",
    "        {\n",
    "            \"train\": train_channel,\n",
    "            \"validation\": validation_channel,\n",
    "            \"images\": image_channel\n",
    "        },\n",
    "        include_cls_metadata=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: While the model(s) are training\n",
    "\n",
    "**TODO: Training notes** (Go and finish off the other notebooks!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if (WITH_HPO):\n",
    "    if (predictor_hpo):\n",
    "        predictor_hpo.delete_endpoint()\n",
    "    print(\"Deploying HPO model...\")\n",
    "    predictor_hpo = tuner.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m4.xlarge\"\n",
    "    )\n",
    "else:\n",
    "    if (predictor_std):\n",
    "        predictor_std.delete_endpoint()\n",
    "    print(\"Deploying standard (non-HPO) model...\")\n",
    "    predictor_std = estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m4.xlarge\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run inference on test images\n",
    "\n",
    "**TODO: Notes on confidence threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change this if you want something different:\n",
    "predictor = predictor_hpo if WITH_HPO else predictor_std\n",
    "\n",
    "# This time confidence is 0-1, not 0-100:\n",
    "confidence_threshold = 0.2\n",
    "\n",
    "for test_image in os.listdir(test_image_folder):\n",
    "    test_image_path = f\"{test_image_folder}/{test_image}\"\n",
    "    with open(test_image_path, \"rb\") as f:\n",
    "        payload = bytearray(f.read())\n",
    "\n",
    "    client = boto3.client(\"sagemaker-runtime\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=predictor.endpoint,\n",
    "        ContentType='application/x-image',\n",
    "        Body=payload\n",
    "    )\n",
    "\n",
    "    result = response['Body'].read()\n",
    "    result = json.loads(result)[\"prediction\"]\n",
    "    # result is a list of [class_ix, confidence, y1, y2, x1, x2] detections.\n",
    "    display(HTML(f\"<h4>{test_image}</h4>\"))\n",
    "    util.visualize_detection(\n",
    "        test_image_path,\n",
    "        result,\n",
    "        CLASS_NAMES,\n",
    "        thresh=confidence_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Although training instances are ephemeral, the resources we allocated for real-time endpoints need to be cleaned up to avoid ongoing charges.\n",
    "\n",
    "The code below will delete the *most recently deployed* endpoint for the HPO and non-HPO configurations, but note that if you deployed either more than once, you might end up with extra endpoints.\n",
    "\n",
    "To be safe, it's best to still check through the SageMaker console for any left-over resources when cleaning up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (predictor_hpo):\n",
    "    print(\"Deleting HPO-optimized predictor endpoint\")\n",
    "    predictor_hpo.delete_endpoint()\n",
    "if (predictor_std):\n",
    "    print(\"Deleting standard (non-HPO) predictor endpoint\")\n",
    "    predictor_std.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review TODO\n",
    "\n",
    "**TODO: Review**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
